{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 24: Markov Matrices; Fourier Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference    \n",
    "Lecture video: https://www.youtube.com/watch?v=lGGDIGizcQ0             \n",
    "Chinese note: https://nbviewer.jupyter.org/github/zlotus/notes-linear-algebra/blob/master/chapter24.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$A=\\left[\\begin{array}{ccc}0.1 & 0.01 & 0.3 \\\\ 0.2 & 0.99 & 0.3 \\\\ 0.7 & 0 & 0.4\\end{array}\\right]$ is a Markov matrix. \n",
    "\n",
    "Markvo matrix have the following two properties:\n",
    "* All the elements are larger than 0\n",
    "* The sum of each column is 1\n",
    "\n",
    "For Markov matrices, we are more interested in the steady state in the power operation. \n",
    "\n",
    "In fact from the above two properties, we have the following facts:\n",
    "* One of the eigenvalues is 1\n",
    "* The absolute value of other eigenvalues are smaller than 1\n",
    "\n",
    "From the power operation of matrix we have:\n",
    "$$u_{k}=A^{k} u_{0}=S \\Lambda^{k} S^{-1} u_{0}=S \\Lambda^{k} S^{-1} S c=S \\Lambda^{k} c=c_{1} \\lambda_{1}^{k} x_{1}+c_{2} \\lambda_{2}^{k} x_{2}+\\cdots+c_{n} \\lambda_{n}^{k} x$$\n",
    "It is easy to see that if $\\lambda_1=1$ and the absolute values of other eigenvalues are samller than 1, then as times goes, $k\\rightarrow \\infty$ and we reaches the steady state $u_k = c_1x_1$. \n",
    "\n",
    "Let's see the first property using matrix $A$. $A-I=\\left[\\begin{array}{ccc}-0.9 & 0.01 & 0.3 \\\\ 0.2 & -0.01 & 0.3 \\\\ 0.7 & 0 & -0.6\\end{array}\\right]$. We can see that the sum of each column becomes 0. Then the sum of all row vectors becomes 0, which indicates that the rows are linearly dependent. Thus $A-I$ is singlular. From the fact that the sum of all row vectors becomes 0, we can also have $\\left[\\begin{array}{c}1 \\\\ 1 \\\\ \\vdots \\\\ 1\\end{array}\\right]^{\\top}$ is in the left null space of $A-I$. The eigenvector of eigenvalue 1 is in the null space of $A-I$ because $A x=x \\rightarrow(A-I) x=0$. \n",
    "\n",
    "A little comment: the eigenvalue of matrix $A$ is identical to the eigenvalue of $A^{\\top}$. The 10th property of determinant is $\\operatorname{det}(A)=\\operatorname{det}(A^{\\top})$. Then if $\\operatorname{det}(A-\\lambda I)=0$, we have $\\operatorname{det}(A-\\lambda I)^{T}=0 \\Longrightarrow = \\operatorname{det}\\left(A^{T}-\\lambda I\\right)=0$. \n",
    "\n",
    "Now we compute the corresponding eigenvector of eigenvalue 1. $$(A-I) x_{1}=0 \\Longrightarrow x_{1}=\\left[\\begin{array}{c}\n",
    "0.6 \\\\\n",
    "33 \\\\\n",
    "0.7\n",
    "\\end{array}\\right]$$\n",
    "\n",
    "Next we talk about the application of Markov matrices using an exmaple of population transition between California and Massachusetts: \n",
    "$$\n",
    "\\underbrace{\\left[\\begin{array}{c}\n",
    "u_{c a l} \\\\\n",
    "u_{m a s s}\n",
    "\\end{array}\\right]_{k+1}}_{u_{k+1}}=\\underbrace{\\left[\\begin{array}{cc}\n",
    "0.9 & 0.2 \\\\\n",
    "0.1 & 0.8\n",
    "\\end{array}\\right]}_\\text{Markov matrix $A$}\\underbrace{\\left[\\begin{array}{c}\n",
    "u_{c a l} \\\\\n",
    "u_{m a s s}\n",
    "\\end{array}\\right]_{k}}_{u_k}\n",
    "$$\n",
    "The above equation means that 10% California people will go to Massachestts and 20% Massachusetts people will go to California at every time step. \n",
    "\n",
    "Suppose initial state is $\\left[\\begin{array}{c}u_{c a l} \\\\ u_{\\text {mass }}\\end{array}\\right]_{0}=\\left[\\begin{array}{c}0 \\\\ 1000\\end{array}\\right]$ï¼Œ after one time step $\\left[\\begin{array}{c}u_{c a l} \\\\ u_{m a s s}\\end{array}\\right]_{1}=\\left[\\begin{array}{cc}0.9 & 0.2 \\\\ 0.1 & 0.8\\end{array}\\right]\\left[\\begin{array}{c}0 \\\\ 1000\\end{array}\\right]=\\left[\\begin{array}{c}200 \\\\ 800\\end{array}\\right]$. As time goes, more people will go to California while some Carlifornia people will move to Massachusetts. \n",
    "\n",
    "Let's compute the eigenvalues: Markov matrix has an eigenvalue $\\lambda_1 = 1$; $\\lambda_2 = 0.7$ from trace. \n",
    "The corresponding eigenvectors: $\\lambda_1 = 1, x_{1}=\\left[\\begin{array}{l}\n",
    "2 \\\\\n",
    "1\n",
    "\\end{array}\\right]$. In fact, now we can get the steady result after infinite steps: $u_{\\infty}=c_{1}\\left[\\begin{array}{l}2 \\\\ 1\\end{array}\\right]$. Because the total population does not change, thus $c_1 = \\frac{1000}{3}$. When the steady state is reached, $\\left[\\begin{array}{c}u_{c a l} \\\\ u_{m a s s}\\end{array}\\right]_{\\infty}=\\left[\\begin{array}{c}\\frac{2000}{3} \\\\ \\frac{1000}{3}\\end{array}\\right]$. \n",
    "\n",
    "The another eigenvector $\\lambda_2 = 0.7, x_2 =\\left[\\begin{array}{c}\n",
    "-1 \\\\\n",
    "1\n",
    "\\end{array}\\right] $. $ u_{k}=c_{1} 1^{k}\\left[\\begin{array}{l}\n",
    "2 \\\\\n",
    "1\n",
    "\\end{array}\\right]+c_{2} 0.7^{k}\\left[\\begin{array}{c}\n",
    "-1 \\\\\n",
    "1\n",
    "\\end{array}\\right]$. We can solve $c_1, c_2$ by using $u_{0}=\\left[\\begin{array}{c}\n",
    "0 \\\\\n",
    "1000\n",
    "\\end{array}\\right]=c_{1}\\left[\\begin{array}{l}\n",
    "2 \\\\\n",
    "1\n",
    "\\end{array}\\right]+c_{2}\\left[\\begin{array}{c}\n",
    "-1 \\\\\n",
    "1\n",
    "\\end{array}\\right] \\Longrightarrow c_{1}=\\frac{1000}{3}, c_{2}=\\frac{2000}{3}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Fourier Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first have review on projection before moving to Fourier series. \n",
    "\n",
    "Suppose $q_{1}, q_{2}, \\cdots q_{n}$ are an orthonormal basis. Then vector $v$ in the space spanned by the basis can expressed as  $v=x_{1} q_{1}+x_{2} q_{2}+\\cdots+x_{n} q_{n}$. Now we want to know the value of coefficient $x_i$, e.g., $x_1$. What's a formula for $x_1$? Using the property of orthonormal vectors, we can have:\n",
    "$$q_1^{\\top}v = q_1^{\\top} (x_{1} q_{1}+x_{2} q_{2}+\\cdots+x_{n} q_{n}) = x_1$$\n",
    "\n",
    "The matrix form is:\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{llll}\n",
    "q_{1} & q_{2} & \\cdots & q_{n}\n",
    "\\end{array}\\right]\\left[\\begin{array}{c}\n",
    "x_{1} \\\\\n",
    "x_{2} \\\\\n",
    "\\vdots \\\\\n",
    "x_{n}\n",
    "\\end{array}\\right]=v \\Longrightarrow Qx = v, x= Q^{-1}v, x = Q^{\\top}v\n",
    "$$\n",
    "\n",
    "Thus for each element of $x$:\n",
    "$$\n",
    "x_{i}=q_{i}^{T} v_{\\text {o }}\n",
    "$$\n",
    "\n",
    "Now we move to Fourier seriers. The expansion of Fourier seriers is:\n",
    "\n",
    "$$\n",
    "f(x)=a_{0}+a_{1} \\cos x+b_{1} \\sin x+a_{2} \\cos 2 x+b_{2} \\sin 2 x+\\cdots\n",
    "$$\n",
    "\n",
    "Similar to what we have done to $v$, we can also expand $f(x)$ in function space.  $f(x)$ in function space is the $v$ in vector space; $1, \\cos x, \\sin x, \\cos 2 x, \\sin 2 x, \\cdots $ is the $q_{1}, q_{2}, \\cdots q_{n}$ in vector space. The difference is that the function space is infinite thus it $f(x)$ needs infinite functions as basis to represent. \n",
    "\n",
    "Next we talk about \"Orthognal functions\". For two vectors are orthogonal, we have $v^{T} w=v_{1} w_{1}+v_{2} w_{2}+\\cdots+v_{n} w_{n}=0$. We can also compute the inner product of f(x) and g(x), $f(x) \\cdot g(x)$ and sum up. Suppose the functions are continuous, then the inner product is:\n",
    "\n",
    "$$\n",
    "f^{T} g=\\int f(x) g(x) \\mathrm{d} x\n",
    "$$\n",
    "\n",
    "The Fourier series uses sine cosine  whose period is $2\\pi$, thus the product of two functions in Fourier series can be written:\n",
    "\n",
    "$$\n",
    "f^{T} g=\\int_{0}^{2 \\pi} f(x) g(x) \\mathrm{d} x\n",
    "$$\n",
    "For example, if $f(x)= \\sin x, g(x)= \\cos x$, then:\n",
    "\n",
    "$$\n",
    "\\int_{0}^{2 \\pi} \\sin x \\cos x \\mathrm{~d} x=\\left.\\frac{1}{2} \\sin ^{2} x\\right|_{0} ^{2 \\pi}=0\n",
    "$$\n",
    "\n",
    "Lastly, we see how to calculate the coefficient of $\\cos x$. Similar to how we calculate $x_1$, we muliply $\\cos x$: \n",
    "\n",
    "$$\n",
    "\\int_{0}^{2 \\pi} f(x) \\cos x \\mathrm{~d} x=a_{1} \\int_{0}^{2 \\pi} \\cos ^{2} x \\mathrm{~d} x\n",
    "$$\n",
    "\n",
    "$$\n",
    "a_{1} \\pi=\\int_{0}^{2 \\pi} f(x) \\cos x \\mathrm{~d} x \\rightarrow a_{1}=\\frac{1}{\\pi} \\int_{0}^{2 \\pi} f(x) \\cos x \\mathrm{~d} x\n",
    "$$\n",
    "\n",
    "We have shown how $f(x)$ is expanded using a orthonormal basis in function space. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
