{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 25: Quiz2 Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference    \n",
    "Lecture video: https://www.youtube.com/watch?v=QuZL5IKpO_U             \n",
    "Chinese note: https://nbviewer.jupyter.org/github/zlotus/notes-linear-algebra/blob/master/chapter25.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have learned?\n",
    "* Orthonormality. For an orthognal matrix $Q=\\left[\\begin{array}{llll}q_{1} & q_{2} & \\cdots & q_{n}\\end{array}\\right]$, its column vectors are orthormal to each other. We have $Q^{\\top} Q=I$\n",
    "* Projection. Projection matrix $P= A\\left(A^{T} A\\right)^{-1} A^{T}$\n",
    "* Gram-Schmidt to get orthonormal basis. \n",
    "* Determinant: property 1-3 then we induced property 4-10\n",
    "* Calculate determinant using cofactors\n",
    "* Calculate inverse matrix using cofactors: $\n",
    "A^{-1}=\\frac{1}{\\operatorname{det} A} C^{\\top}\n",
    "$\n",
    "* Eigenvalues and eigenvectors: $A x=\\lambda x$, compute egienvalues and eigenvectors by $\\operatorname{det}(A-\\lambda I)=0$\n",
    "* Matrix diagonalizatio through $AS = \\Lambda S$: $A=S^{-1}\\Lambda S$. \n",
    "* The power of matrix: $A^{k}=S \\Lambda^{k} S^{-1}$\n",
    "\n",
    "Next we will solve the problem:\n",
    "\n",
    "1. Find the projection matrix of $a=\\left[\\begin{array}{l}2 \\\\ 1 \\\\ 2\\end{array}\\right]$:\n",
    " $$\n",
    "a \\perp(b-p) \\rightarrow A^{T}(b-A \\hat{x})=0 \\rightarrow \\hat{x}=\\left(A^{T} A\\right)^{-1} A^{T} b \\rightarrow p = A \\hat{x}=A\\left(A^{T} A\\right)^{-1} A^{T} b=P b\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\underline{P=A\\left(A^{T} A\\right)^{-1} A^{T}} \\stackrel{a}{=} \\frac{a a^{T}}{a^{T}a}=\\frac{1}{9}\\left[\\begin{array}{lll}\n",
    "4 & 2 & 4 \\\\\n",
    "2 & 1 & 2 \\\\\n",
    "4 & 2 & 4\n",
    "\\end{array}\\right] .\n",
    "$$\n",
    "\n",
    "* The rank of $P$ is 1.  \n",
    "* The column space is a line through (2, 1, 2). The dimension of column space is 1.\n",
    "* The null space is 2 dimensional. Thus two of its eigenvalues are 0 $\\lambda_1=\\lambda_2=0$. According to its trace is 1, we can know that $\\lambda_3=1$\n",
    "* The eigenvector of $\\lambda_3=1$ is $a=\\left[\\begin{array}{l}2 \\\\ 1 \\\\ 2\\end{array}\\right]$. Because $P$ is the projection matrix of $a$, which means that $P$ will transform any vector into the column space of $a$, if that vector is already in the column space of $a$, then we have $Pa = a$. Thus $a$ is the eigenvector of $P$ with eigenvalue $1$. \n",
    "* $u_{k+1}=P u_{k}, u_{0}=\\left[\\begin{array}{l}9 \\\\ 9 \\\\ 0\\end{array}\\right]$, find $u_k$. The normal way is: $$A S=S \\Lambda \\rightarrow A=S \\Lambda S^{-1} \\rightarrow u_{k+1}=A u_{k}=A^{k+1} u_{0}, u_{0}=S c \\rightarrow u_{k+1}=S \\Lambda^{k+1}c$$\n",
    "\n",
    "$$\n",
    "u_k = A^{k} u_{0}=c_{1} \\lambda_{1}^{k} x_{1}+c_{2} \\lambda_{2}^{k} x_{2}+\\cdots+c_{n} \\lambda_{n}^{k} x_{n}\n",
    "$$\n",
    "But here $P$ is a projection matrix, we can easily compute $u_k = P^ku_0 = Pu_0=\\left[\\begin{array}{l}\n",
    "6 \\\\\n",
    "3 \\\\\n",
    "6\n",
    "\\end{array}\\right]$. \n",
    "\n",
    "2. It is about linear regression. Fit (1,4),(2,5),(3,8) into a line through origin: $y=Dt$. $\\left[\\begin{array}{l}1 \\\\ 2 \\\\ 3\\end{array}\\right] =\\left[\\begin{array}{l}4 \\\\ 5 \\\\ 8\\end{array}\\right]$, $AD=b$, but obviously there is not solution. We should use $A^{T} A \\hat{D}=A^{T} b$ to calculate the best possible solution. $14 D=38, \\hat{D}=\\frac{38}{14} \\rightarrow y=\\frac{38}{14} t$. We have projected $b$ into the column space of $a$ and thus found the best possible solution. \n",
    "\n",
    "3. Compute the orthogonal vectors of $a_{1}=\\left[\\begin{array}{l}1 \\\\ 2 \\\\ 3\\end{array}\\right] a_{2}=\\left[\\begin{array}{l}1 \\\\ 1 \\\\ 1\\end{array}\\right]$: The two vectors spans a plane which is the column space of matrix $A=\\left[a_{1}, a_{2}\\right]$, we want to find the orthogonal basis for the plane. Using Gram-Schmidt, first start with $a_1$ and find the part of $a_2$ that orthogonal to $a_1$.   $a_{2}-x a_{1}=a_{2}-\\frac{a_{1}^{T} a_{2}}{a_{1}^{T} a_{1}} a_{1}=\\left[\\begin{array}{l}1 \\\\ 1 \\\\ 1\\end{array}\\right]-\\frac{6}{14}\\left[\\begin{array}{l}1 \\\\ 2 \\\\ 3\\end{array}\\right]$\n",
    "\n",
    "4.  $4\\times 4 $ matrix $A$, its eigenvalues are $\\lambda_{1}, \\lambda_{2}, \\lambda_{3}, \\lambda_{4}$. What is the condition that matrix $A$ is invertible? If matrix is invertible, then the null space has only 0 vectors. Thus $Ax = 0x$ only has one solution, which is 0. It means that 0 can not be the eigenvalue of matrix $A$. \n",
    "    * What is $\\operatorname{det} A^{-1}$? $\\operatorname{det} A^{-1}=\\frac{1}{\\operatorname{det} A} = \\frac{1}{\\lambda_{1} \\lambda_{2} \\lambda_{3} \\lambda_{4}}$\n",
    "    * What is the trace of $(A+I)$? $\\operatorname{trace}(A+I)=a_{11}+1+a_{22}+1+a_{33}+1+a_{44}+1=\\lambda_{1}+\\lambda_{2}+\\lambda_{3}+\\lambda_{4}+4$\n",
    "\n",
    "5. Suppose matrix  $A_{4}=\\left[\\begin{array}{llll}1 & 1 & 0 & 0 \\\\ 1 & 1 & 1 & 0 \\\\ 0 & 1 & 1 & 1 \\\\ 0 & 0 & 1 & 1\\end{array}\\right]$\n",
    "    * Find that $D_n = \\_ D_{n-1} + \\_  D_{n-2}$. \n",
    "    \n",
    "    We use cofactors along the fisrt row, $\\operatorname{det} A_{4}=1 \\cdot\\left|\\begin{array}{lll}1 & 1 & 0 \\\\ 1 & 1 & 1 \\\\ 0 & 1 & 1\\end{array}\\right|-1 \\cdot\\left|\\begin{array}{lll}1 & 1 & 0 \\\\ 0 & 1 & 1 \\\\ 0 & 1 & 1\\end{array}\\right|=1 \\cdot\\left|\\begin{array}{lll}1 & 1 & 0 \\\\ 1 & 1 & 1 \\\\ 0 & 1 & 1\\end{array}\\right|-1 \\cdot\\left|\\begin{array}{ll}1 & 1 \\\\ 1 & 1\\end{array}\\right|=\\operatorname{det} A_{3}-\\operatorname{det} A_{2}$. We have  $D_{n}=D_{n-1}-D_{n-2}, D_{1}=1, D_{2}=0$. \n",
    "    * How to solve $D_{n}=D_{n-1}-D_{n-2}$?\n",
    "    \n",
    "    First build the euqation system as $\\left\\{\\begin{array}{ll}D_{n} & =D_{n-1}-D_{n-2} \\\\ D_{n-1} & =D_{n-1}\\end{array}\\right. \\Longrightarrow \\left[\\begin{array}{c}\n",
    "D_{n} \\\\\n",
    "D_{n-1}\n",
    "\\end{array}\\right]=\\left[\\begin{array}{cc}\n",
    "1 & -1 \\\\\n",
    "1 & 0\n",
    "\\end{array}\\right]\\left[\\begin{array}{c}\n",
    "D_{n-1} \\\\\n",
    "D_{n-2}\n",
    "\\end{array}\\right]$. Find the eigenvalue and eigenvector of $\\left[\\begin{array}{cc}\n",
    "1 & -1 \\\\\n",
    "1 & 0\n",
    "\\end{array}\\right]$, which can be calculated by solving $\\left|\\begin{array}{cc}1-\\lambda & -1 \\\\ 1 & -\\lambda\\end{array}\\right|=\\lambda^{2}-\\lambda+1=0 \\Longrightarrow \\lambda_{1}=\\frac{1+\\sqrt{3} i}{2}, \\lambda_{2}=\\frac{1-\\sqrt{3} i}{2}$. The magnitude is $\\frac{1}{4}+\\frac{3}{4}=1$. They are in the circle $e^{i \\theta}$, whihc is $\\cos \\theta+i \\sin \\theta$. In this example, $\\theta = 60^{\\circ}$. Thus we can rewrite the eigenvalues as $\\lambda_{1}=e^{i \\pi / 3}, \\lambda_{2}=e^{-i \\pi / 3}$. Six powers of the eigenvalues gives us 1. And 6 is the period. This means that the result will neither converge nor diverge. It will just periodically goes around. \n",
    "\n",
    "6. Suppose $A_{4}=\\left[\\begin{array}{llll}0 & 1 & 0 & 0 \\\\ 1 & 0 & 2 & 0 \\\\ 0 & 2 & 0 & 3 \\\\ 0 & 0 & 3 & 0\\end{array}\\right]$, $A_{3}=\\left[\\begin{array}{lll}0 & 1 & 0 \\\\ 1 & 0 & 2 \\\\ 0 & 2 & 0\\end{array}\\right]$. \n",
    "    * Find the projection matrix that projects into the column space of $A_3$. $A_3$ is singular. We can find the projection matrix through  $P=A\\left(A^{T} A\\right) A^{T}$. \n",
    "\n",
    "    * Find the eigenvalue and eigenvector of $A_3$. \n",
    "        $$\n",
    "\\left|A_{3}-\\lambda I\\right|=\\left|\\begin{array}{ccc}\n",
    "-\\lambda & 1 & 0 \\\\\n",
    "1 & -\\lambda & 2 \\\\\n",
    "0 & 2 & -\\lambda\n",
    "\\end{array}\\right|=-\\lambda^{3}+5 \\lambda=0 \\Longrightarrow \\lambda_{1}=0, \\lambda_{2}=\\sqrt{5}, \\lambda_{3}=-\\sqrt{5}\n",
    "$$\n",
    "    * Find the projection matrix that projects into the column space of $A_4$\n",
    "    \n",
    "    Use $P=A\\left(A^{T} A\\right) A^{T}$? Okay but no need. We can first see that the determinant of $A_4$ is 0. This indicates that $A_4$ is invertible. Then all the vectors in $\\mathbb{R}^{4}$ will be in the column space of $A_4$. Their projection will always be themselves. Thus $P=I$. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
