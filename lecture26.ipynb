{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 26: Symmetric Matrices and Positive Definiteness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference    \n",
    "Lecture video: https://www.youtube.com/watch?v=UCc9q_cAhho             \n",
    "Chinese note: https://nbviewer.jupyter.org/github/zlotus/notes-linear-algebra/blob/master/chapter26.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetric Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we have learned the eigenvalues and eigenvectors of matrices. We have also seen some speical matrices and their eigenvlalues, eignevectors. For example, Markov matrices have an eigenvalue 1. \n",
    "\n",
    "This lecture we talk about real symmetric matrices. Firstly we give two properties of symmetric matrices:\n",
    "1. Their eigenvalues are real.\n",
    "2. Their eigenvectors are orthonormal.\n",
    "\n",
    "The typical case is that eigenvalues are not reapeated and the eigenvectors are orthonormal. \n",
    "\n",
    "Usually, a matric can be diagnolized: $A=S \\Lambda S^{-1}$. If $A$ is symmetric, then the column vectors of $S$ are orthonormal to each other. Thus $S$ is actually an orthogonal matrix. Thus for symmetric matrix $A$, we can diagnolize it as: $A=Q \\Lambda Q^{-1} = Q \\Lambda Q^{\\top}$. We can see that this equation is also symmetric which is concistent with the fact that $A$ is also symmetric:\n",
    "$$\n",
    "A^{\\top}=\\left(Q \\Lambda Q^{T}\\right)^{T}=\\left(Q^{T}\\right)^{T} \\Lambda^{T} Q^{T}=Q \\Lambda Q^{T} = A\n",
    "$$\n",
    "\n",
    "$A== Q \\Lambda Q^{\\top}$ is named as `spectral theorem`. The spectral here means the set of all eigenvalues. It comes from the light spectrum which is the composition of pure things just as $A$ can be decomposed into eigenvalues and eigenvectors. \n",
    "\n",
    "Now we prove the first property: the eigenvalues of symmetric matrices are real numbers. \n",
    "\n",
    "For any matrix $Ax = \\lambda x$, since we consider real symmetric matrix here its conjugate form is $A\\bar{x}=\\bar{\\lambda} \\bar{x}$. Transform the both sides and multiply $x$, we have: $\\bar{x}^{T} Ax=\\bar{x}^{T} \\bar{\\lambda}x$. Multiply $\\bar{x}^{T}$ on the both sides of $Ax = \\lambda x$, we have: $\\bar{x}^{T} A x=\\bar{x}^{T} \\lambda x$. Thus we have:\n",
    "\n",
    "$$\\bar{x}^{T} Ax=\\bar{x}^{T} \\bar{\\lambda}x = \\bar{x}^{T} \\lambda x$$\n",
    "\n",
    "$\\bar{x}^{T} x=\\left[\\begin{array}{llll}\\bar{x}_{1} & \\bar{x}_{2} & \\cdots & \\bar{x}_{n}\\end{array}\\right]\\left[\\begin{array}{c}x_{1} \\\\ x_{2} \\\\ \\vdots \\\\ x_{n}\\end{array}\\right]=\\bar{x}_{1} x_{1}+\\bar{x}_{2} x_{2}+\\cdots+\\bar{x}_{n} x_{n} >0$. Thus $\\bar{\\lambda} = \\lambda$. \n",
    "\n",
    "If $A$ is a complex matrix, if we want the above reasoning process still holds, we need $A=\\bar{A}^{T}$. These matrix are called `good matrices` by the professor.\n",
    "\n",
    "Let's take a further step: \n",
    "\n",
    "$$A=Q \\Lambda Q^{T}=\\left[\\begin{array}{llll}\n",
    "q_{1} & q_{2} & \\cdots & q_{n}\n",
    "\\end{array}\\right]\\left[\\begin{array}{cccc}\n",
    "\\lambda_{1} & & \\cdots & \\\\\n",
    "& \\lambda_{2} & \\cdots & \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "& & \\cdots & \\lambda_{n}\n",
    "\\end{array}\\right]\\left[\\begin{array}{c}\n",
    "q_{1}^{T} \\\\\n",
    "q_{1}^{T} \\\\\n",
    "\\vdots \\\\\n",
    "q_{1}^{T}\n",
    "\\end{array}\\right]=\\lambda_{1} q_{1} q_{1}^{T}+\\lambda_{2} q_{2} q_{2}^{T}+\\cdots+\\lambda_{n} q_{n} q_{n}^{T} $$\n",
    "\n",
    "$qq^{\\top}$ is actually a projection matrix: $\\frac{q q^{T}}{q^{T} q}=q q^{T}$. If satisfies the property that its square is itself. \n",
    "\n",
    "Therefore we have the conclusion that: **Every symmetric matrix is a combination of mutually perpendicular projection matrix.**  Another great fact about symmetric matrix is that: **the signs of the pivots are the same as signs of $\\lambda$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive definite matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive definite matrix is a subclass of symmetric matrix whose eigenvalues are positive. Also all the pitovts are positive. \n",
    "\n",
    "For example, $\\left[\\begin{array}{ll}5 & 2 \\\\ 2 & 3\\end{array}\\right]$. Its pivots are : 5, $\\frac{11}{5}$.  We can compute the eigenvalues through $\\left|\\begin{array}{cc}5-\\lambda & 2 \\\\ 2 & 3-\\lambda\\end{array}\\right|=\\lambda^{2}-8 \\lambda+11=0 \\rightarrow \\lambda=4 \\pm \\sqrt{5}$. They are all positive. Moreover, the product of pivots are the same as the product of eigenvalues, which is the determinant of the matrix. \n",
    "\n",
    "There is one other fact about positive definite matrix is that **all sub-determinants of positive definite matrix is positive**. For the above matrix, $|5|=5,\\left|\\begin{array}{ll}5 & 2 \\\\ 2 & 3\\end{array}\\right|=11$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
